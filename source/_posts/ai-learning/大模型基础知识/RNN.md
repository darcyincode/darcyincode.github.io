---
title: RNN（循环神经网络）
date: 2026-02-04
categories:
  - [大模型, 神经网络基础]
tags:
  - RNN
  - 神经网络
  - 深度学习
---

# RNN（循环神经网络）

## 什么是RNN？

RNN (Recurrent Neural Network，循环神经网络) 是一种专门用于处理**序列数据**的神经网络。与传统前馈神经网络不同，RNN具有"记忆"能力，能够利用之前时间步的信息来影响当前的输出。

## 基本原理

### 核心思想

RNN的关键在于**隐藏状态**（Hidden State）的循环连接：
- 当前时刻的隐藏状态不仅依赖于当前输入，还依赖于上一时刻的隐藏状态
- 这种循环结构使得网络能够保持对历史信息的"记忆"

### 数学表示

在时刻 $t$，RNN的计算过程如下：

#### 隐藏状态更新
$$h_t = \tanh(W_{hh} \cdot h_{t-1} + W_{xh} \cdot x_t + b_h)$$

#### 输出计算
$$y_t = W_{hy} \cdot h_t + b_y$$

**参数说明：**
- $x_t$: 时刻 $t$ 的输入
- $h_t$: 时刻 $t$ 的隐藏状态
- $h_{t-1}$: 上一时刻的隐藏状态
- $y_t$: 时刻 $t$ 的输出
- $W_{hh}$: 隐藏状态到隐藏状态的权重矩阵
- $W_{xh}$: 输入到隐藏状态的权重矩阵
- $W_{hy}$: 隐藏状态到输出的权重矩阵
- $b_h, b_y$: 偏置项

### 网络结构展开

RNN可以沿时间轴展开：

```
时刻:    t-1        t         t+1
         ↓          ↓          ↓
输入:   x_{t-1}    x_t      x_{t+1}
         ↓          ↓          ↓
       ┌───┐      ┌───┐      ┌───┐
   →   │ h │  →   │ h │  →   │ h │  →
       └───┘      └───┘      └───┘
         ↓          ↓          ↓
输出:   y_{t-1}    y_t      y_{t+1}
```

## 训练方法：BPTT

RNN使用**BPTT (Backpropagation Through Time，通过时间反向传播)** 进行训练：

1. 将RNN沿时间轴展开成深度网络
2. 使用标准反向传播算法计算梯度
3. 梯度需要从当前时刻反向传播到所有历史时刻

## 为什么有长期依赖问题？

### 问题本质

RNN在处理长序列时，难以学习距离较远的时间步之间的依赖关系。这主要源于**梯度消失**和**梯度爆炸**问题。

### 梯度消失问题详解

#### 1. 梯度传播链

在BPTT中，梯度需要通过多个时间步反向传播。假设我们要计算损失 $L$ 对 $t$ 时刻之前第 $k$ 个时间步的梯度：

$$\frac{\partial L}{\partial h_{t-k}} = \frac{\partial L}{\partial h_t} \cdot \prod_{i=1}^{k} \frac{\partial h_{t-i+1}}{\partial h_{t-i}}$$

#### 2. 雅可比矩阵连乘

每个 $\frac{\partial h_{t-i+1}}{\partial h_{t-i}}$ 是一个雅可比矩阵，其主要成分包含权重矩阵 $W_{hh}$ 和激活函数的导数：

$$\frac{\partial h_t}{\partial h_{t-1}} = W_{hh}^T \cdot \text{diag}(\tanh'(h_{t-1}))$$

#### 3. 梯度消失的数学原因

**当 $k$ 很大时（长距离依赖）：**

- **如果** $|W_{hh}| < 1$ 或 $|\tanh'| < 1$：
  - 连乘导致：$|W_{hh}|^k \to 0$
  - **梯度消失**：早期时间步的梯度趋近于0
  - **后果**：网络无法学习长期依赖

- **如果** $|W_{hh}| > 1$：
  - 连乘导致：$|W_{hh}|^k \to \infty$
  - **梯度爆炸**：梯度值变得极大
  - **后果**：训练不稳定，参数更新剧烈波动

### 直观理解

```
时间跨度越大 → 梯度传播路径越长 → 连乘次数越多
                                      ↓
                            |W| < 1: 梯度趋近0（消失）
                            |W| > 1: 梯度爆炸
```

### 具体例子

假设我们在分析句子："**我在法国长大**...（中间100个词）...**所以我说流利的法语**"

- RNN需要记住"法国"这个信息100个时间步
- 梯度需要反向传播100步才能更新"法国"相关的权重
- 经过100次矩阵连乘，梯度可能已经消失到接近0
- 网络无法学到"法国"和"法语"之间的关联

### tanh激活函数的影响

$$\tanh'(x) = 1 - \tanh^2(x)$$

- $\tanh'(x)$ 的最大值为1，通常远小于1
- 在梯度反向传播中，每经过一个时间步，梯度都会被 $\tanh'$ 缩小
- 经过多个时间步后，梯度指数级衰减

## RNN的局限性总结

| 问题 | 原因 | 影响 |
|------|------|------|
| 梯度消失 | 长距离梯度连乘导致指数衰减 | 无法学习长期依赖 |
| 梯度爆炸 | 权重矩阵特征值>1时连乘发散 | 训练不稳定 |
| 记忆容量有限 | 隐藏状态不断被覆盖 | 早期信息丢失 |
| 难以并行 | 序列计算依赖前一时刻 | 训练效率低 |

## RNN的应用场景

尽管有局限性，RNN在某些场景下仍然有效：

- ✅ **短序列任务**：文本分类、情感分析
- ✅ **时间序列预测**：股票价格、天气预报
- ✅ **序列标注**：词性标注、命名实体识别
- ✅ **语音识别**（短音频片段）

## 解决方案

为了克服RNN的长期依赖问题，研究者提出了多种改进方案：

### 1. LSTM（长短期记忆网络）
- 引入门控机制和细胞状态
- 允许梯度无损传播
- **最成功的RNN变体**

### 2. GRU（门控循环单元）
- LSTM的简化版本
- 参数更少，训练更快
- 性能与LSTM相当

### 3. 梯度裁剪（Gradient Clipping）
- 限制梯度的最大范数
- 缓解梯度爆炸问题
- 治标不治本

### 4. 更好的初始化策略
- 正交初始化
- 单位矩阵初始化
- 部分缓解梯度消失

### 5. 注意力机制（Attention）
- 允许模型直接访问所有历史信息
- 绕过了长距离梯度传播问题
- 催生了Transformer架构

## 关键要点

1. **RNN的优势**：能够处理变长序列，具有参数共享和记忆能力
2. **核心缺陷**：长期依赖问题源于梯度的指数衰减或爆炸
3. **数学本质**：梯度反向传播时的矩阵连乘导致数值不稳定
4. **实践意义**：理解RNN的局限性是学习LSTM、GRU和Transformer的基础
