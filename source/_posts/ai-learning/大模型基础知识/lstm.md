
---
title: LSTM（长短期记忆网络）
date: 2026-02-07
order: 4
categories:
  - [大模型, 神经网络基础]
tags:
  - LSTM
  - RNN
  - 神经网络
  - 深度学习
  - 门控机制
---

# LSTM（长短期记忆网络）

## 什么是LSTM？

LSTM (Long Short-Term Memory) 是一种特殊的循环神经网络（RNN），专门设计用来解决传统RNN的**长期依赖问题**（即难以记住较早时间步的信息）。

## 核心技术

### 1. 细胞状态（Cell State）- 记忆高速公路

- 信息流贯穿整个序列的"传送带"
- 允许信息长距离传递且梯度不易消失

### 2. 三个门控机制（Gating Mechanisms）

#### 遗忘门（Forget Gate）
决定从细胞状态中丢弃哪些信息

$$f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$$

#### 输入门（Input Gate）
决定哪些新信息存储到细胞状态

$$i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$$

$$\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$$

#### 输出门（Output Gate）
决定输出什么信息

$$o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$$

### 3. 状态更新

#### 细胞状态更新
$$C_t = f_t \ast C_{t-1} + i_t \ast \tilde{C}_t$$

#### 隐藏状态输出
$$h_t = o_t \ast \tanh(C_t)$$

## 核心优势

- ✅ 解决梯度消失问题
- ✅ 捕获长期依赖关系
- ✅ 选择性记忆和遗忘信息

## 典型应用

- 语言建模
- 机器翻译
- 语音识别
- 时间序列预测
- 情感分析
- 视频分析

## LSTM vs 传统RNN

| 特性 | 传统RNN | LSTM |
|------|---------|------|
| 梯度问题 | 容易梯度消失/爆炸 | 有效缓解 |
| 长期依赖 | 难以学习 | 擅长捕获 |
| 参数量 | 少 | 多（约4倍） |
| 训练速度 | 快 | 较慢 |
| 性能 | 短序列较好 | 长序列优秀 |

## 工作流程示意

```
输入 x_t 和上一时刻隐藏状态 h_{t-1}
    ↓
遗忘门：决定遗忘多少旧记忆
    ↓
输入门：决定添加多少新信息
    ↓
更新细胞状态 C_t
    ↓
输出门：决定输出什么
    ↓
输出 h_t（隐藏状态）
```

## 关键创新点

LSTM的核心创新在于**门控机制**和**细胞状态**的设计：

1. **可选择性记忆**：通过门控制信息流动
2. **长期记忆通道**：细胞状态允许信息无损传递
3. **梯度友好**：避免了传统RNN的梯度消失问题
